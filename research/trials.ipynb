{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e11d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c635c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e73cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db937635",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e80dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pypdf loader:\n",
    "# Used to load and extract text from a single PDF file. It converts each page of the PDF into a LangChain Document object with text and metadata.\n",
    "#Directoryloader:\n",
    "# load multiple files from a directory. \n",
    "# In this case, it scans a folder and applies PyPDFLoader to every PDF file found.\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "\n",
    "# This class is used to split large text into smaller chunks.(essential in RAG (Retrieval-Augmented Generation) systems because LLMs have context length limits.)\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b397156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract text from pdf files\n",
    "# This function takes Data, which represents the path to a directory containing PDF files.\n",
    "def load_pdf_files(Data):\n",
    "    loader=DirectoryLoader(Data,glob=\"*.pdf\",\n",
    "                           loader_cls=PyPDFLoader) #Data: Directory path where PDF files are stored,glob=\"*.pdf\": Ensures that only PDF files are loaded,loader_cls=PyPDFLoader: Specifies that each PDF file should be processed using PyPDFLoader\n",
    "    \n",
    "    #Loads all PDF files from the directory,Extracts text from each PDF page,onverts them into a list of LangChain Document objects\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1020b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data= load_pdf_files('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cde00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32514a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af7496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List #List: Used for type hints to indicate a list of items\n",
    "from langchain_core.documents import Document #Document: LangChain’s standard object for storing text and metadata\n",
    "\n",
    "#Takes a list of Document objects as input\n",
    "#Returns a new list of Document objects\n",
    "#The returned documents contain minimal metadata\n",
    "\n",
    "def filter_to_minimal_docs(docs: List[Document]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Given a list of Document ojects,return a new list of Document objects\n",
    "    containing only 'source' in metadata and the original page_content.\n",
    "    \"\"\"\n",
    "\n",
    "    minimal_docs: List[Document] =[]  #Creates an empty list to store the cleaned documents\n",
    "    for doc in docs: #Iterates through each Document in the input list\n",
    "        src = doc.metadata.get(\"source\") #Safely retrieves the source value from metadata\n",
    "        minimal_docs.append(\n",
    "            Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={'source': src}\n",
    "            )\n",
    "        ) #Creates a new Document object\n",
    "        #copies Original text (page_content),Only the source field in metadata\n",
    "\n",
    "    return minimal_docs #Returns the list of simplified Document objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87012f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_docs= filter_to_minimal_docs(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f7cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119077de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunking- split the docs into smaller chunks\n",
    "\n",
    "def text_split(minimal_docs):\n",
    "    text_splitter= RecursiveCharacterTextSplitter( #Splits text recursively using separators like:[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "        chunk_size=500, #Each text chunk will have maximum 1000 characters.\n",
    "        chunk_overlap=20, #Each chunk shares 200 characters with the previous chunk,Ensures context continuity across chunks.\n",
    "    )\n",
    "\n",
    "    texts_chunk=text_splitter.split_documents(minimal_docs) #Splits each document into smaller Document chunks.\n",
    "    return texts_chunk #Returns a list of chunked Document objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4978d981",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_chunk= text_split(minimal_docs)\n",
    "print(f'Number of chunks : {len(texts_chunk)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff8b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cf4a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding model- to convert text into numbers so LLM can understand\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "def download_embedding():\n",
    "    '''\n",
    "    Download and return the HuggingFace embeddings model.\n",
    "    '''\n",
    "    model_name='sentence-transformers/all-MiniLM-L6-v2'\n",
    "    embeddings= HuggingFaceEmbeddings(\n",
    "        model_name=model_name,\n",
    "    \n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "embedding= download_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470eaa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2434ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector=embedding.embed_query(\"Hello world\")\n",
    "vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vector length\", len(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bbbc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will store vector embeddings to pinecone vector DB\n",
    "#we will load env file where we stored API keys\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02adeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To access this credentials:\n",
    "PINECONE_API_KEY= os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"]=PINECONE_API_KEY #this sets the Pinecone key back into the Python runtime environment.\n",
    "os.environ['OPENAI_API_KEY']=OPENAI_API_KEY #you want to ensure the key is available during execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffab5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will import pinecone\n",
    "\n",
    "from pinecone import Pinecone\n",
    "Pinecone_api_key=PINECONE_API_KEY\n",
    "\n",
    "#autenticate pinecone acc\n",
    "pc= Pinecone(api_key=Pinecone_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31eca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d1c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Index/DB\n",
    "from pinecone import Pinecone, ServerlessSpec #tells which cloud to use\n",
    "\n",
    "# initialize client\n",
    "pc = Pinecone()\n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384, #dimension of embeddings\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b35000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will store our vectors\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch=PineconeVectorStore.from_documents(\n",
    "    documents=texts_chunk,\n",
    "    embedding= embedding,\n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429bd97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add  more data to the existing pinecone index\n",
    "dswith=Document(\n",
    "    page_content='learning a full chatbot project',\n",
    "    metadata={'source':'youtube'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a88e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch.add_documents(documents=[dswith])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c76297",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever( #Converts Pinecone vector store into a retriever object\n",
    "    search_type='similarity',\n",
    "    search_kwargs={'k': 3} #Top 3 most relevant chunks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fd79a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs= retriever.invoke(\"What is acne?\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efc1cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatmodel=ChatOpenAI(\n",
    "    model='gpt-4o'\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd860f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import some necessary library\n",
    "from langchain.chains import create_retrieval_chain #Connects Retriever → LLM\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain #Combines retrieved documents into one prompt\n",
    "from langchain_core.prompts import ChatPromptTemplate #how context + question are given to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f74459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#systemprompt--Defines rules for the LLM\n",
    "#Tells the model:Use only retrieved context,Don’t hallucinate,Be concise\n",
    "system_prompt=(\n",
    "    'You are a Medical assistant for question-answering tasks.'\n",
    "    'Use the following piece of retrieved context to answer'\n",
    "    'the question.If you dont know the question,say that you'\n",
    "    'dont know.Use three sentences maximum and keep the answer concise.'\n",
    "    '\\n\\n'\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt= ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",system_prompt),#rules + context\n",
    "        (\"human\",\"{input}\") #user’s question\n",
    "    ]\n",
    ")\n",
    "\n",
    "#User Question\n",
    "    #  ↓\n",
    "# Retriever (Pinecone)\n",
    "    #  ↓\n",
    "# Top-K Relevant Chunks\n",
    "    #  ↓\n",
    "# Prompt (system + context + question)\n",
    "    #  ↓\n",
    "# LLM Answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769a19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain=create_stuff_documents_chain(chatmodel,prompt)  #chatmodel:LLM, Prompt-System + Human prompt\n",
    "rag_chain=create_retrieval_chain(retriever,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8504223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=rag_chain.invoke({\"input\":\"what is Acromegaly and gigantism?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
